# ecommerce-analytics
This is project uses synthetic ecommerce data to showcase tools and techniques to extract, transform, store, and analyze the data.


# Project Outline

E-commerce Churn Prediction with Synthetic Data
Project Status: Work in Progress

## Overview

This project focuses on building an end-to-end churn prediction model for an e-commerce business using synthetically generated data. The synthetic data will incorporate various churn patterns, simulating realistic customer behavior. The project will cover data generation, exploration, model development, and deployment using Streamlit.

## Key Components:

### Synthetic Data Generation
    
- Generate e-commerce data including customers, products, orders, and website interactions using Python libraries like faker, numpy, and pandas.

- Implement multiple churn patterns (sudden and gradual) with varying decline functions to create a diverse and realistic dataset.

### Data Exploration and Analysis

- Conduct exploratory data analysis (EDA) to understand the characteristics of the generated data.

- Visualize churn patterns and identify key features that might be indicative of churn.

### Churn Prediction Model Development

- Preprocess the data and engineer relevant features for churn prediction.
- Train and evaluate various machine learning models (e.g., logistic regression, decision trees, random forests) to predict customer churn.
- Select the best-performing model based on evaluation metrics.

### Streamlit Deployment
- Build an interactive Streamlit application to:
    - Visualize key metrics and insights from the data.
    - Make predictions using the trained churn model.

### Project Goals:

- Demonstrate proficiency in synthetic data generation with complex patterns.
- Showcase data exploration and analysis skills.
- Build and evaluate machine learning models for churn prediction.
- Deploy an interactive application using Streamlit.

### Current Progress:

[x] ~Synthetic data generation with multiple churn patterns implemented.~

[] Initial data exploration and visualization

[] Model development

[] Continue with feature engineering and model training.

[] Fine-tune the selected model and evaluate its performance.

[] Develop the Streamlit application for interactive visualization and prediction.

### Libraries Used:

`Python`, `faker`, `numpy`, `scikitlearn`, `pandas`, `streamlit`

### How to Run (Once Completed):

Clone the repository.
Install the required dependencies using `pip install -r requirements.txt.`


# Disclaimer:

This project is a work in progress.

The synthetic data is for illustrative purposes and might not perfectly reflect real-world e-commerce data.

Feel free to contribute or provide feedback!
